{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NASSMA] Simple ConvNet example.",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nassma2019/PracticalSessions/blob/master/vision/baseline_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SPYepgHVQPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmX7dFevVS6a",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "185c0d29-56e7-4ae2-e161-8f1517edc10a"
      },
      "source": [
        "#@title Loading the cifar10 dataset and minor pre-processing.\n",
        "(train_inputs, train_labels), (test_inputs, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Normalizing inputs into the [-1, 1.] range.\n",
        "train_inputs = 2 * (train_inputs / 255.) - 1\n",
        "test_inputs = 2 * (test_inputs / 255.) - 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZU4Nf4-Wa8n",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Model architecture.\n",
        "FILTERS = [64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512] #@param\n",
        "STRIDES = [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1] #@param\n",
        "NUM_CLASSES = 10 #@param\n",
        "\n",
        "assert len(FILTERS) == len(STRIDES)\n",
        "NUM_LAYERS = len(FILTERS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGVevOTuVawm",
        "colab_type": "code",
        "outputId": "82abddba-4f83-4c17-efcf-5d6b4f8df230",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "#@title Model definition.\n",
        "tf.reset_default_graph()\n",
        "x = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "print(\"Filters: %s\" % FILTERS)\n",
        "print(\"Strides: %s\" % STRIDES)\n",
        "print(\"\")\n",
        "print(\"Input shape = %s\" % x.shape)\n",
        "print(\"\")\n",
        "\n",
        "y = x\n",
        "for i in range(NUM_LAYERS):\n",
        "  print(\"Layer #%d:\" % i)\n",
        "  y = tf.keras.layers.Conv2D(filters=FILTERS[i], strides=STRIDES[i],\n",
        "                             kernel_size=(3, 3), padding='SAME')(y)\n",
        "  y = tf.keras.layers.BatchNormalization()(y)\n",
        "  y = tf.keras.layers.ReLU()(y)\n",
        "  print(\"  - Output shape = %s\" % y.shape)\n",
        "\n",
        "print(\"\")\n",
        "y = tf.keras.layers.Lambda(lambda t : tf.reduce_mean(t, reduction_indices=[1, 2]),\n",
        "                          name='reduce_mean')(y)\n",
        "print(\"Shape after `reduce_mean`: %s\" % y.shape)\n",
        "y = tf.keras.layers.Dense(NUM_CLASSES)(y)\n",
        "y = tf.keras.layers.Softmax()(y)\n",
        "print(\"Final output shape: %s\" % y.shape)\n",
        "model = tf.keras.Model(inputs=x, outputs=y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filters: [64, 64, 128, 128, 128, 256, 256, 256, 512, 512, 512]\n",
            "Strides: [1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1]\n",
            "\n",
            "Input shape = (?, 32, 32, 3)\n",
            "\n",
            "Layer #0:\n",
            "  - Output shape = (?, 32, 32, 64)\n",
            "Layer #1:\n",
            "  - Output shape = (?, 32, 32, 64)\n",
            "Layer #2:\n",
            "  - Output shape = (?, 16, 16, 128)\n",
            "Layer #3:\n",
            "  - Output shape = (?, 16, 16, 128)\n",
            "Layer #4:\n",
            "  - Output shape = (?, 16, 16, 128)\n",
            "Layer #5:\n",
            "  - Output shape = (?, 8, 8, 256)\n",
            "Layer #6:\n",
            "  - Output shape = (?, 8, 8, 256)\n",
            "Layer #7:\n",
            "  - Output shape = (?, 8, 8, 256)\n",
            "Layer #8:\n",
            "  - Output shape = (?, 4, 4, 512)\n",
            "Layer #9:\n",
            "  - Output shape = (?, 4, 4, 512)\n",
            "Layer #10:\n",
            "  - Output shape = (?, 4, 4, 512)\n",
            "\n",
            "Shape after `reduce_mean`: (?, 512)\n",
            "Final output shape: (?, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUfb2PaObsfm",
        "colab_type": "code",
        "outputId": "b050ea21-819d-4216-e186-7fd9cf645b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "re_lu_10 (ReLU)              (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "reduce_mean (Lambda)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,799,242\n",
            "Trainable params: 7,793,610\n",
            "Non-trainable params: 5,632\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxFdTA1JY6GU",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Train the model.\n",
        "# Note: does not converge as quickly as the original model.\n",
        "# (no data augmentation / different optimizer)\n",
        "optimizer = tf.keras.optimizers.Adagrad(lr=0.1, decay=1e-6)\n",
        "model.compile(optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_inputs, train_labels_one_hot, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}